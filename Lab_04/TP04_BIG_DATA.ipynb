{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "0️⃣ Colab Setup – Fast PySpark Installation"
      ],
      "metadata": {
        "id": "fvrNs1fjp2tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PySpark (fast, ~50MB)\n",
        "!pip install -q pyspark\n",
        "\n",
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "\n",
        "# Initialize Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"TP4_SparkMLlib\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Optional: Check Spark version\n",
        "spark.version\n"
      ],
      "metadata": {
        "id": "GIZCWoRHp3wj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3b31917-174b-4f61-aada-327d75bdf777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.5.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ Load all CSV files into a single DataFrame"
      ],
      "metadata": {
        "id": "D81eUA0Up_Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Get all CSV file paths\n",
        "csv_files = glob.glob(\"/content/drive/MyDrive/data*.csv\")  # change path if needed\n",
        "\n",
        "# Load all CSVs into a single DataFrame\n",
        "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/content/drive/MyDrive/data/*.csv\")\n",
        "\n",
        "# Preview first 5 rows\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MqV9BT4qAhj",
        "outputId": "6a8c08e0-d99f-4c74-94c9-8c4b8c10b736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "|   537226|    22811|SET OF 6 T-LIGHTS...|       6|2010-12-06 08:34:00|     2.95|   15987.0|United Kingdom|\n",
            "|   537226|    21713|CITRONELLA CANDLE...|       8|2010-12-06 08:34:00|      2.1|   15987.0|United Kingdom|\n",
            "|   537226|    22927|GREEN GIANT GARDE...|       2|2010-12-06 08:34:00|     5.95|   15987.0|United Kingdom|\n",
            "|   537226|    20802|SMALL GLASS SUNDA...|       6|2010-12-06 08:34:00|     1.65|   15987.0|United Kingdom|\n",
            "|   537226|    22052|VINTAGE CARAVAN G...|      25|2010-12-06 08:34:00|     0.42|   15987.0|United Kingdom|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2️⃣ Fill missing values (NaN) with 0"
      ],
      "metadata": {
        "id": "P5fUfJsps5iM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col  # ⚠️ import col\n",
        "\n",
        "# Fill all missing values with 0\n",
        "df = df.fillna(0)"
      ],
      "metadata": {
        "id": "ADDoQRgWs6LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3️⃣ Add day_of_week column from InvoiceDate"
      ],
      "metadata": {
        "id": "_UW-OVl3tWWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import dayofweek, to_date, col\n",
        "\n",
        "# Convert InvoiceDate to proper date type\n",
        "df = df.withColumn(\"InvoiceDate\", to_date(col(\"InvoiceDate\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
        "\n",
        "# Add day_of_week column (1 = Sunday, 7 = Saturday)\n",
        "df = df.withColumn(\"day_of_week\", dayofweek(col(\"InvoiceDate\")))\n",
        "\n",
        "# Preview\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKg865N3tW8T",
        "outputId": "99b5b173-881e-4571-fdc3-9081c2c74726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+-----------+\n",
            "|InvoiceNo|StockCode|         Description|Quantity|InvoiceDate|UnitPrice|CustomerID|       Country|day_of_week|\n",
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+-----------+\n",
            "|   537226|    22811|SET OF 6 T-LIGHTS...|       6| 2010-12-06|     2.95|   15987.0|United Kingdom|          2|\n",
            "|   537226|    21713|CITRONELLA CANDLE...|       8| 2010-12-06|      2.1|   15987.0|United Kingdom|          2|\n",
            "|   537226|    22927|GREEN GIANT GARDE...|       2| 2010-12-06|     5.95|   15987.0|United Kingdom|          2|\n",
            "|   537226|    20802|SMALL GLASS SUNDA...|       6| 2010-12-06|     1.65|   15987.0|United Kingdom|          2|\n",
            "|   537226|    22052|VINTAGE CARAVAN G...|      25| 2010-12-06|     0.42|   15987.0|United Kingdom|          2|\n",
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4️⃣ Split into training and test sets"
      ],
      "metadata": {
        "id": "TNkICS39tvzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training: purchases before 2010-12-13\n",
        "train_df = df.filter(col(\"InvoiceDate\") < \"2010-12-13\")\n",
        "\n",
        "# Test: purchases on or after 2010-12-13\n",
        "test_df = df.filter(col(\"InvoiceDate\") >= \"2010-12-13\")\n",
        "\n",
        "# Check counts\n",
        "print(\"Training rows:\", train_df.count())\n",
        "print(\"Test rows:\", test_df.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgSNEKpOtwZc",
        "outputId": "6034da48-cc2f-429d-8b2d-e83fd67998b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training rows: 26732\n",
            "Test rows: 18676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6️⃣ Create a StringIndexer for day_of_week"
      ],
      "metadata": {
        "id": "A7RMmYEOuE1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Step 6: create StringIndexer\n",
        "indexer = StringIndexer(inputCol=\"day_of_week\", outputCol=\"day_of_week_indexed\")\n",
        "\n",
        "# Fit and transform on training data\n",
        "train_indexed = indexer.fit(train_df).transform(train_df)\n",
        "\n",
        "# Show first 5 rows\n",
        "train_indexed.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNvlI0vPuJHD",
        "outputId": "07ec005c-cb24-487d-df46-dc825181f1f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+\n",
            "|InvoiceNo|StockCode|         Description|Quantity|InvoiceDate|UnitPrice|CustomerID|       Country|day_of_week|day_of_week_indexed|\n",
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+\n",
            "|   537226|    22811|SET OF 6 T-LIGHTS...|       6| 2010-12-06|     2.95|   15987.0|United Kingdom|          2|                4.0|\n",
            "|   537226|    21713|CITRONELLA CANDLE...|       8| 2010-12-06|      2.1|   15987.0|United Kingdom|          2|                4.0|\n",
            "|   537226|    22927|GREEN GIANT GARDE...|       2| 2010-12-06|     5.95|   15987.0|United Kingdom|          2|                4.0|\n",
            "|   537226|    20802|SMALL GLASS SUNDA...|       6| 2010-12-06|     1.65|   15987.0|United Kingdom|          2|                4.0|\n",
            "|   537226|    22052|VINTAGE CARAVAN G...|      25| 2010-12-06|     0.42|   15987.0|United Kingdom|          2|                4.0|\n",
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7️⃣ Discussion question :\n",
        "Spark represents weekdays numerically (like Monday = 1, Saturday = 6).\n",
        "But this makes it seem like Saturday > Monday, which isn’t meaningful.\n",
        "✅ To fix this, we use OneHotEncoder, which creates a binary vector representation instead of ranking them numerically."
      ],
      "metadata": {
        "id": "WS6Z4gkgvKd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2️⃣ OneHotEncoder to fix the ordinal problem\n",
        "encoder = OneHotEncoder(inputCols=[\"day_of_week_indexed\"], outputCols=[\"day_of_week_encoded\"])\n",
        "train_encoded = encoder.fit(train_indexed).transform(train_indexed)\n",
        "\n",
        "# Show first 5 rows after OneHotEncoding\n",
        "train_encoded.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOuI-D7ivcNh",
        "outputId": "2e9758b7-efbd-42df-b27d-3d046f84daad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+\n",
            "|InvoiceNo|StockCode|Description                   |Quantity|InvoiceDate|UnitPrice|CustomerID|Country       |day_of_week|day_of_week_indexed|day_of_week_encoded|\n",
            "+---------+---------+------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+\n",
            "|537226   |22811    |SET OF 6 T-LIGHTS CACTI       |6       |2010-12-06 |2.95     |15987.0   |United Kingdom|2          |4.0                |(5,[4],[1.0])      |\n",
            "|537226   |21713    |CITRONELLA CANDLE FLOWERPOT   |8       |2010-12-06 |2.1      |15987.0   |United Kingdom|2          |4.0                |(5,[4],[1.0])      |\n",
            "|537226   |22927    |GREEN GIANT GARDEN THERMOMETER|2       |2010-12-06 |5.95     |15987.0   |United Kingdom|2          |4.0                |(5,[4],[1.0])      |\n",
            "|537226   |20802    |SMALL GLASS SUNDAE DISH CLEAR |6       |2010-12-06 |1.65     |15987.0   |United Kingdom|2          |4.0                |(5,[4],[1.0])      |\n",
            "|537226   |22052    |VINTAGE CARAVAN GIFT WRAP     |25      |2010-12-06 |0.42     |15987.0   |United Kingdom|2          |4.0                |(5,[4],[1.0])      |\n",
            "+---------+---------+------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8️⃣ Add VectorAssembler for features"
      ],
      "metadata": {
        "id": "eDcbILTfwZkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Assemble all features into a single vector column\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"UnitPrice\", \"Quantity\", \"day_of_week_encoded\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "train_features = assembler.transform(train_encoded)\n",
        "\n",
        "# Show first 5 rows to check the features\n",
        "train_features.select(\"UnitPrice\", \"Quantity\", \"day_of_week_encoded\", \"features\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-__kMyO8waGQ",
        "outputId": "71992512-bed8-4068-d8e9-734c997fa975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------------------+---------------------------+\n",
            "|UnitPrice|Quantity|day_of_week_encoded|features                   |\n",
            "+---------+--------+-------------------+---------------------------+\n",
            "|2.95     |6       |(5,[4],[1.0])      |(7,[0,1,6],[2.95,6.0,1.0]) |\n",
            "|2.1      |8       |(5,[4],[1.0])      |(7,[0,1,6],[2.1,8.0,1.0])  |\n",
            "|5.95     |2       |(5,[4],[1.0])      |(7,[0,1,6],[5.95,2.0,1.0]) |\n",
            "|1.65     |6       |(5,[4],[1.0])      |(7,[0,1,6],[1.65,6.0,1.0]) |\n",
            "|0.42     |25      |(5,[4],[1.0])      |(7,[0,1,6],[0.42,25.0,1.0])|\n",
            "+---------+--------+-------------------+---------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Create Pipeline"
      ],
      "metadata": {
        "id": "bJePbOVIw8t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline(stages=[indexer, encoder, assembler])\n",
        "pipeline_model = pipeline.fit(train_df)\n",
        "train_transformed = pipeline_model.transform(train_df)\n",
        "\n",
        "# Show first 5 rows of final features\n",
        "train_transformed.select(\"UnitPrice\", \"Quantity\", \"day_of_week_encoded\", \"features\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GTkEaeMw-H0",
        "outputId": "ed9952c0-fda2-49b8-d801-d0dba250606f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------------------+---------------------------+\n",
            "|UnitPrice|Quantity|day_of_week_encoded|features                   |\n",
            "+---------+--------+-------------------+---------------------------+\n",
            "|2.95     |6       |(5,[4],[1.0])      |(7,[0,1,6],[2.95,6.0,1.0]) |\n",
            "|2.1      |8       |(5,[4],[1.0])      |(7,[0,1,6],[2.1,8.0,1.0])  |\n",
            "|5.95     |2       |(5,[4],[1.0])      |(7,[0,1,6],[5.95,2.0,1.0]) |\n",
            "|1.65     |6       |(5,[4],[1.0])      |(7,[0,1,6],[1.65,6.0,1.0]) |\n",
            "|0.42     |25      |(5,[4],[1.0])      |(7,[0,1,6],[0.42,25.0,1.0])|\n",
            "+---------+--------+-------------------+---------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10: StringIndexer must know the number of unique values\n",
        "**Problem**: StringIndexer needs to know how many unique categories exist to properly encode them.\n",
        "\n",
        "**Solution**:\n",
        "\n",
        "Fit the StringIndexer on the training set, not the test set.\n",
        "\n",
        "Spark automatically detects the number of unique categories during .fit().\n",
        "\n",
        "Example :"
      ],
      "metadata": {
        "id": "zjXsoBQWxWIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"day_of_week\", outputCol=\"day_of_week_indexed\")\n",
        "indexer_model = indexer.fit(train_df)  # Spark detects unique values automatically\n",
        "train_indexed = indexer_model.transform(train_df)\n",
        "\n",
        "# Show first 5 rows\n",
        "train_indexed.select(\"day_of_week\", \"day_of_week_indexed\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA9emMPLxggj",
        "outputId": "79c39d9f-47bd-4434-bc00-9d97e127207e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------------+\n",
            "|day_of_week|day_of_week_indexed|\n",
            "+-----------+-------------------+\n",
            "|          2|                4.0|\n",
            "|          2|                4.0|\n",
            "|          2|                4.0|\n",
            "|          2|                4.0|\n",
            "|          2|                4.0|\n",
            "+-----------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 11: Transform training set using pipeline"
      ],
      "metadata": {
        "id": "a3M46-ZJyBXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Define pipeline: StringIndexer → OneHotEncoder → VectorAssembler\n",
        "pipeline = Pipeline(stages=[indexer, encoder, assembler])\n",
        "pipeline_model = pipeline.fit(train_df)  # Fit on training set\n",
        "pipeline_model = pipeline.fit(test_df)\n",
        "# Transform training data\n",
        "train_transformed = pipeline_model.transform(train_df)\n",
        "test_transformed = pipeline_model.transform(test_df)\n",
        "# Show first 5 rows\n",
        "train_transformed.show(5, truncate=False)\n",
        "test_transformed.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRDr6jo8yDM8",
        "outputId": "be6497aa-e64e-47fc-8966-35f7fdfd3703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+---------------------------+\n",
            "|InvoiceNo|StockCode|Description                   |Quantity|InvoiceDate|UnitPrice|CustomerID|Country       |day_of_week|day_of_week_indexed|day_of_week_encoded|features                   |\n",
            "+---------+---------+------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+---------------------------+\n",
            "|537226   |22811    |SET OF 6 T-LIGHTS CACTI       |6       |2010-12-06 |2.95     |15987.0   |United Kingdom|2          |1.0                |(5,[1],[1.0])      |(7,[0,1,3],[2.95,6.0,1.0]) |\n",
            "|537226   |21713    |CITRONELLA CANDLE FLOWERPOT   |8       |2010-12-06 |2.1      |15987.0   |United Kingdom|2          |1.0                |(5,[1],[1.0])      |(7,[0,1,3],[2.1,8.0,1.0])  |\n",
            "|537226   |22927    |GREEN GIANT GARDEN THERMOMETER|2       |2010-12-06 |5.95     |15987.0   |United Kingdom|2          |1.0                |(5,[1],[1.0])      |(7,[0,1,3],[5.95,2.0,1.0]) |\n",
            "|537226   |20802    |SMALL GLASS SUNDAE DISH CLEAR |6       |2010-12-06 |1.65     |15987.0   |United Kingdom|2          |1.0                |(5,[1],[1.0])      |(7,[0,1,3],[1.65,6.0,1.0]) |\n",
            "|537226   |22052    |VINTAGE CARAVAN GIFT WRAP     |25      |2010-12-06 |0.42     |15987.0   |United Kingdom|2          |1.0                |(5,[1],[1.0])      |(7,[0,1,3],[0.42,25.0,1.0])|\n",
            "+---------+---------+------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+---------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+---------+---------+-----------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+---------------------------+\n",
            "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate|UnitPrice|CustomerID|Country       |day_of_week|day_of_week_indexed|day_of_week_encoded|features                   |\n",
            "+---------+---------+-----------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+---------------------------+\n",
            "|539325   |22720    |SET OF 3 CAKE TINS PANTRY DESIGN   |3       |2010-12-17 |4.95     |13004.0   |United Kingdom|6          |3.0                |(5,[3],[1.0])      |(7,[0,1,5],[4.95,3.0,1.0]) |\n",
            "|539325   |22722    |SET OF 6 SPICE TINS PANTRY DESIGN  |4       |2010-12-17 |3.95     |13004.0   |United Kingdom|6          |3.0                |(5,[3],[1.0])      |(7,[0,1,5],[3.95,4.0,1.0]) |\n",
            "|539325   |22915    |ASSORTED BOTTLE TOP  MAGNETS       |12      |2010-12-17 |0.42     |13004.0   |United Kingdom|6          |3.0                |(5,[3],[1.0])      |(7,[0,1,5],[0.42,12.0,1.0])|\n",
            "|539325   |22922    |FRIDGE MAGNETS US DINER ASSORTED   |12      |2010-12-17 |0.85     |13004.0   |United Kingdom|6          |3.0                |(5,[3],[1.0])      |(7,[0,1,5],[0.85,12.0,1.0])|\n",
            "|539325   |22923    |FRIDGE MAGNETS LES ENFANTS ASSORTED|12      |2010-12-17 |0.85     |13004.0   |United Kingdom|6          |3.0                |(5,[3],[1.0])      |(7,[0,1,5],[0.85,12.0,1.0])|\n",
            "+---------+---------+-----------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+---------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 12: Create KMeans instance"
      ],
      "metadata": {
        "id": "2uAaBvXxyn-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "# Create KMeans with 20 clusters\n",
        "kmeans = KMeans(featuresCol=\"features\", predictionCol=\"cluster\", k=20, seed=42)\n"
      ],
      "metadata": {
        "id": "ubw0Cw6Xyocf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 13: Fit KMeans on training data"
      ],
      "metadata": {
        "id": "XeQog-dQyrsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_model_train = kmeans.fit(train_transformed)\n",
        "\n",
        "\n",
        "# Transform training set to get cluster assignments\n",
        "train_clusters = kmeans_model_train.transform(train_transformed)\n",
        "\n",
        "# Show first 5 rows with clusters\n",
        "train_clusters.select(\"UnitPrice\", \"Quantity\", \"day_of_week_encoded\", \"features\", \"cluster\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNtOBkwxysJM",
        "outputId": "0fee5f7e-6210-4cfd-84d7-9cd4676c88cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------------------+---------------------------+-------+\n",
            "|UnitPrice|Quantity|day_of_week_encoded|features                   |cluster|\n",
            "+---------+--------+-------------------+---------------------------+-------+\n",
            "|2.95     |6       |(5,[1],[1.0])      |(7,[0,1,3],[2.95,6.0,1.0]) |11     |\n",
            "|2.1      |8       |(5,[1],[1.0])      |(7,[0,1,3],[2.1,8.0,1.0])  |11     |\n",
            "|5.95     |2       |(5,[1],[1.0])      |(7,[0,1,3],[5.95,2.0,1.0]) |11     |\n",
            "|1.65     |6       |(5,[1],[1.0])      |(7,[0,1,3],[1.65,6.0,1.0]) |11     |\n",
            "|0.42     |25      |(5,[1],[1.0])      |(7,[0,1,3],[0.42,25.0,1.0])|0      |\n",
            "+---------+--------+-------------------+---------------------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 14: Make predictions on test set"
      ],
      "metadata": {
        "id": "9Gpk6hswzcAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform test set using the same pipeline\n",
        "test_transformed = pipeline_model.transform(test_df)\n",
        "\n",
        "# Predict clusters on test set using the trained KMeans model\n",
        "test_clusters = kmeans_model_train.transform(test_transformed)\n",
        "\n",
        "# Show first 5 rows\n",
        "test_clusters.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQvZi8uszcdO",
        "outputId": "165f4cfb-57d5-48f7-cb53-145e2b323987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+-----------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+---------------------------+-------+\n",
            "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate|UnitPrice|CustomerID|Country       |day_of_week|day_of_week_indexed|day_of_week_encoded|features                   |cluster|\n",
            "+---------+---------+-----------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+---------------------------+-------+\n",
            "|539325   |22720    |SET OF 3 CAKE TINS PANTRY DESIGN   |3       |2010-12-17 |4.95     |13004.0   |United Kingdom|6          |3.0                |(5,[3],[1.0])      |(7,[0,1,5],[4.95,3.0,1.0]) |11     |\n",
            "|539325   |22722    |SET OF 6 SPICE TINS PANTRY DESIGN  |4       |2010-12-17 |3.95     |13004.0   |United Kingdom|6          |3.0                |(5,[3],[1.0])      |(7,[0,1,5],[3.95,4.0,1.0]) |11     |\n",
            "|539325   |22915    |ASSORTED BOTTLE TOP  MAGNETS       |12      |2010-12-17 |0.42     |13004.0   |United Kingdom|6          |3.0                |(5,[3],[1.0])      |(7,[0,1,5],[0.42,12.0,1.0])|0      |\n",
            "|539325   |22922    |FRIDGE MAGNETS US DINER ASSORTED   |12      |2010-12-17 |0.85     |13004.0   |United Kingdom|6          |3.0                |(5,[3],[1.0])      |(7,[0,1,5],[0.85,12.0,1.0])|0      |\n",
            "|539325   |22923    |FRIDGE MAGNETS LES ENFANTS ASSORTED|12      |2010-12-17 |0.85     |13004.0   |United Kingdom|6          |3.0                |(5,[3],[1.0])      |(7,[0,1,5],[0.85,12.0,1.0])|0      |\n",
            "+---------+---------+-----------------------------------+--------+-----------+---------+----------+--------------+-----------+-------------------+-------------------+---------------------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 15: Compute silhouette score"
      ],
      "metadata": {
        "id": "hfzQ_RlVz1uD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "\n",
        "evaluator = ClusteringEvaluator(featuresCol=\"features\", predictionCol=\"cluster\", metricName=\"silhouette\", distanceMeasure=\"squaredEuclidean\")\n",
        "\n",
        "silhouette = evaluator.evaluate(test_clusters)\n",
        "print(f\"Silhouette score: {silhouette}\")\n"
      ],
      "metadata": {
        "id": "Ilr1GqKuz2Qg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e5a088-a441-45f0-a8c9-b3f28c0f8a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette score: 0.743506843337969\n"
          ]
        }
      ]
    }
  ]
}